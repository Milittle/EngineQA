# Runtime baseline
APP_HOST=127.0.0.1
APP_PORT=8080
FRONTEND_PORT=5173

# Backend runtime switch used by scripts/dev.sh
# - rust: use backend/ (Axum)
# - python: use backend-python/ (FastAPI)
BACKEND_RUNTIME=python

# Vector store settings (Rust backend)
VECTOR_STORE=lancedb
LANCEDB_URI=./.lancedb
LANCEDB_TABLE=knowledge_chunks
VECTOR_SCORE_THRESHOLD=0.3
EMBEDDING_VECTOR_SIZE=1536

# Python backend vector store settings (embedded only)
QDRANT_LOCAL_PATH=./.qdrant-local
QDRANT_COLLECTION=knowledge_chunks

# Inference provider
INFER_PROVIDER=internal_api
INTERNAL_API_BASE_URL=<required>
INTERNAL_API_TOKEN=<required>

# Optional split endpoint config (recommended when chat/embed addresses differ).
# If unset, both endpoints fall back to INTERNAL_API_BASE_URL.
INTERNAL_API_CHAT_BASE_URL=
INTERNAL_API_EMBED_BASE_URL=
# Optional split tokens (fallback to INTERNAL_API_TOKEN)
INTERNAL_API_CHAT_TOKEN=
INTERNAL_API_EMBED_TOKEN=

INTERNAL_API_CHAT_PATH=/chat/completions
INTERNAL_API_EMBED_PATH=/embeddings
INTERNAL_API_CHAT_MODEL=GLM-4.7
INTERNAL_API_EMBED_MODEL=embedding-3

# Reliability controls
LLM_TIMEOUT_MS=12000
EMBED_TIMEOUT_MS=5000
OUTBOUND_MAX_CONCURRENCY=8
CHAT_RATE_LIMIT_RPM=120
CHAT_BURST=10
RETRY_CHAT_MAX=1
RETRY_EMBED_MAX=3

# Offline indexer
KNOWLEDGE_DIR=./knowledge
